{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "Number of images in x_train 60000\n",
      "Number of images in x_test 10000\n"
     ]
    }
   ],
   "source": [
    "# Format data for keras API; this data-preparation section advised by linked website\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "img_size = (28, 28, 1)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('Number of images in x_train', x_train.shape[0])\n",
    "print('Number of images in x_test', x_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-17b6bcf5639c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#Use sequential model because based on research that is what seems like is the best for classification CNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "#Use sequential model because based on research that is what seems like is the best for classification CNN\n",
    "model = Sequential()\n",
    "\n",
    "#Perform initial convolution. Activation just linear. 3x3 conv-> valid padding would reduce size to 26x26\n",
    "#adding more filters takes longer, inc acc\n",
    "#Use 3x3 because research suggested 3x3 or 5x5 and our img size was only 28x28\n",
    "model.add(Conv2D(16, kernel_size=(3,3), padding=\"same\", input_shape=img_size))\n",
    "\n",
    "#Perform 2nd conv\n",
    "#Adding more layers takes longer, inc acc\n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\", activation = \"relu\"))\n",
    "#Pooling for feature control for not perfectly aligned data set\n",
    "#Use max pooling because that's what was recommended in Assignment 4 and articles suggested it\n",
    "#Use pooling to downsample more robustly than stride increase\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25)) #dropout for regularization; .25 kind of arbitrary as rate of disassoc.\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\", activation = \"relu\"))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#Flatten array for fully connected layers \n",
    "model.add(Flatten())\n",
    "\n",
    "#Do fc layer with 256 nodes; would do 14x14x64 but that had estimated training time of a day\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "#Adding another fully conn (like 128 or 64) doesnt help and makes training super long\n",
    "model.add(Dense(10,activation=\"softmax\"))\n",
    "\n",
    "#Use adam optimizer and sparse crossentropy loss function based on research. Cross-ent better for classification\n",
    "#Sparse does not require hot encoding, ie that we necessarily hardcode our 10 classes in memory\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Stop if doesnt imporove after 3 epochs\n",
    "checkImprovement = EarlyStopping(patience=3)\n",
    "\n",
    "#Data small enough so fit_generator not rqd\n",
    "model.fit(x=x_train,y=y_train, validation_split=.2, epochs=10, callbacks=[checkImprovement])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use adam optimizer and sparse crossentropy loss function based on research. Cross-ent better for classification\n",
    "#Sparse does not require hot encoding, ie that we necessarily hardcode our 10 classes in memory\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Stop if doesnt imporove after 3 epochs\n",
    "checkImprovement = EarlyStopping(patience=3)\n",
    "\n",
    "#Data small enough so fit_generator not rqd\n",
    "model.fit(x=x_train,y=y_train, validation_split=.2, epochs=10, callbacks=[checkImprovement])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "image_index = 4444\n",
    "plt.imshow(x_test[image_index].reshape(28, 28),cmap='Greys')\n",
    "pred = model.predict(x_test[image_index].reshape(1, 28, 28, 1))\n",
    "print(pred.argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "one = cv2.imread(r'C:\\Users\\MattHetrick\\Documents\\Academics\\Fall 2019\\Cos 429\\Final-Project\\One.jpg')\n",
    "reg1 = cv2.imread(r'C:\\Users\\MattHetrick\\Documents\\Academics\\Fall 2019\\Cos 429\\Final-Project\\New1.jpg')\n",
    "flat2 = cv2.imread(r'C:\\Users\\MattHetrick\\Documents\\Academics\\Fall 2019\\Cos 429\\Final-Project\\Flat2.jpg')\n",
    "two = cv2.imread(r'C:\\Users\\MattHetrick\\Documents\\Academics\\Fall 2019\\Cos 429\\Final-Project\\2.jpg')\n",
    "seven = cv2.imread(r'C:\\Users\\MattHetrick\\Documents\\Academics\\Fall 2019\\Cos 429\\Final-Project\\7.jpg')\n",
    "eight = cv2.imread(r'C:\\Users\\MattHetrick\\Documents\\Academics\\Fall 2019\\Cos 429\\Final-Project\\8.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictNumber(img):\n",
    "    imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    squareGray = imgGray[1000:3500, 0:2500] #square size depends on img but worked for all sample images\n",
    "\n",
    "    resizedSquare = cv2.resize(squareGray, (28, 28), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    #format for keras\n",
    "    squareAsArray = resizedSquare.reshape(28, 28, 1)\n",
    "    squareAsArray = squareAsArray.astype('float32')\n",
    "\n",
    "    #make all black and white, black number\n",
    "    squareAsArray[squareAsArray <= 180.] = 255.\n",
    "    squareAsArray[squareAsArray < 255.] = 0.\n",
    "\n",
    "    #format for keras (again)\n",
    "    squareAsArray /= 255\n",
    "    predictionImage = squareAsArray.reshape(1, 28, 28, 1)\n",
    "    \n",
    "    #visualize image\n",
    "    #plt.imshow(predictionImage.reshape(28,28), cmap = \"Greys\")\n",
    "\n",
    "    pred = model.predict(predictionImage)\n",
    "    \n",
    "    return pred.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.2) /opt/concourse/worker/volumes/live/9523d527-1b9e-48e0-7ed0-a36adde286f0/volume/opencv-suite_1535558719691/work/modules/imgproc/src/color.hpp:253: error: (-215:Assertion failed) VScn::contains(scn) && VDcn::contains(dcn) && VDepth::contains(depth) in function 'CvtHelper'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-deb1f5763d09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictNumber\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtwo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-7f8772fff18f>\u001b[0m in \u001b[0;36mpredictNumber\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredictNumber\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mimgGray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0msquareGray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgGray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2500\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#square size depends on img but worked for all sample images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mresizedSquare\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msquareGray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTER_AREA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(3.4.2) /opt/concourse/worker/volumes/live/9523d527-1b9e-48e0-7ed0-a36adde286f0/volume/opencv-suite_1535558719691/work/modules/imgproc/src/color.hpp:253: error: (-215:Assertion failed) VScn::contains(scn) && VDcn::contains(dcn) && VDepth::contains(depth) in function 'CvtHelper'\n"
     ]
    }
   ],
   "source": [
    "predictNumber(two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
