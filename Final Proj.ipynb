{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format data for keras API; this data-preparation section advised by linked website\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "img_size = (28, 28, 1)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('Number of images in x_train', x_train.shape[0])\n",
    "print('Number of images in x_test', x_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "#Use sequential model because based on research that is what seems like is the best for classification CNN\n",
    "model = Sequential()\n",
    "\n",
    "#Perform initial convolution. Activation just linear. 3x3 conv-> valid padding would reduce size to 26x26\n",
    "#adding more filters takes longer, inc acc\n",
    "#Use 3x3 because research suggested 3x3 or 5x5 and our img size was only 28x28\n",
    "model.add(Conv2D(16, kernel_size=(3,3), padding=\"same\", input_shape=img_size))\n",
    "\n",
    "#Perform 2nd conv\n",
    "#Adding more layers takes longer, inc acc\n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\", activation = \"relu\"))\n",
    "#Pooling for feature control for not perfectly aligned data set\n",
    "#Use max pooling because that's what was recommended in Assignment 4 and articles suggested it\n",
    "#Use pooling to downsample more robustly than stride increase\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25)) #dropout for regularization; .25 kind of arbitrary as rate of disassoc.\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\", activation = \"relu\"))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#Flatten array for fully connected layers \n",
    "model.add(Flatten())\n",
    "\n",
    "#Do fc layer with 256 nodes; would do 14x14x64 but that had estimated training time of a day\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "#Adding another fully conn (like 128 or 64) doesnt help and makes training super long\n",
    "model.add(Dense(10,activation=\"softmax\"))\n",
    "\n",
    "#Use adam optimizer and sparse crossentropy loss function based on research. Cross-ent better for classification\n",
    "#Sparse does not require hot encoding, ie that we necessarily hardcode our 10 classes in memory\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Stop if doesnt imporove after 3 epochs\n",
    "checkImprovement = EarlyStopping(patience=3)\n",
    "\n",
    "#Data small enough so fit_generator not rqd\n",
    "model.fit(x=x_train,y=y_train, validation_split=.2, epochs=10, callbacks=[checkImprovement])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use adam optimizer and sparse crossentropy loss function based on research. Cross-ent better for classification\n",
    "#Sparse does not require hot encoding, ie that we necessarily hardcode our 10 classes in memory\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Stop if doesnt imporove after 3 epochs\n",
    "checkImprovement = EarlyStopping(patience=3)\n",
    "\n",
    "#Data small enough so fit_generator not rqd\n",
    "model.fit(x=x_train,y=y_train, validation_split=.2, epochs=10, callbacks=[checkImprovement])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "image_index = 4444\n",
    "plt.imshow(x_test[image_index].reshape(28, 28),cmap='Greys')\n",
    "pred = model.predict(x_test[image_index].reshape(1, 28, 28, 1))\n",
    "print(pred.argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one = cv2.imread(r'C:\\Users\\MattHetrick\\Documents\\Academics\\Fall 2019\\Cos 429\\Final-Project\\One.jpg')\n",
    "reg1 = cv2.imread(r'C:\\Users\\MattHetrick\\Documents\\Academics\\Fall 2019\\Cos 429\\Final-Project\\New1.jpg')\n",
    "flat2 = cv2.imread(r'C:\\Users\\MattHetrick\\Documents\\Academics\\Fall 2019\\Cos 429\\Final-Project\\Flat2.jpg')\n",
    "two = cv2.imread(r'C:\\Users\\MattHetrick\\Documents\\Academics\\Fall 2019\\Cos 429\\Final-Project\\2.jpg')\n",
    "seven = cv2.imread(r'C:\\Users\\MattHetrick\\Documents\\Academics\\Fall 2019\\Cos 429\\Final-Project\\7.jpg')\n",
    "eight = cv2.imread(r'C:\\Users\\MattHetrick\\Documents\\Academics\\Fall 2019\\Cos 429\\Final-Project\\8.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictNumber(img):\n",
    "    imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    squareGray = imgGray[1000:3500, 0:2500] #square size depends on img but worked for all sample images\n",
    "\n",
    "    resizedSquare = cv2.resize(squareGray, (28, 28), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    #format for keras\n",
    "    squareAsArray = resizedSquare.reshape(28, 28, 1)\n",
    "    squareAsArray = squareAsArray.astype('float32')\n",
    "\n",
    "    #make all black and white, black number\n",
    "    squareAsArray[squareAsArray <= 180.] = 255.\n",
    "    squareAsArray[squareAsArray < 255.] = 0.\n",
    "\n",
    "    #format for keras (again)\n",
    "    squareAsArray /= 255\n",
    "    predictionImage = squareAsArray.reshape(1, 28, 28, 1)\n",
    "    \n",
    "    #visualize image\n",
    "    #plt.imshow(predictionImage.reshape(28,28), cmap = \"Greys\")\n",
    "\n",
    "    pred = model.predict(predictionImage)\n",
    "    \n",
    "    return pred.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictNumber(two)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
